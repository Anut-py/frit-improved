{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08d46086-7679-4ad2-84ef-ad9ffb27c10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ecbd01c-817b-4b0f-90bd-cc056d1a65e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72efa33cde384c7c918fd9ec0dad9383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from model.model import reset_aligned_model\n",
    "# reset_aligned_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf027105-2d52-4052-8781-3e75bfed0ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "from config import OUT_DIR\n",
    "PICKLE_PATH = os.path.join(OUT_DIR, \"datagen.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa6a64fa-a273-49cc-9484-3110bf7273e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PICKLE_PATH, \"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84e9e067-462b-4a4e-b438-387be3ec9d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "kept = []\n",
    "set_aside = []\n",
    "threshold = 3\n",
    "\n",
    "for entry in data:\n",
    "    samples = entry.get('samples', [])\n",
    "    if len(samples) < 2:\n",
    "        continue\n",
    "\n",
    "    scores = [s[1] for s in samples]\n",
    "    max_score = max(scores)\n",
    "    min_score = min(scores)\n",
    "\n",
    "    if max_score - min_score > threshold:\n",
    "        i_max = scores.index(max_score)\n",
    "        i_min = scores.index(min_score)\n",
    "\n",
    "        highest = samples[i_max]\n",
    "        lowest = samples[i_min]\n",
    "\n",
    "        set_aside.append({\n",
    "            'prompt': entry['prompt'],\n",
    "            'original': entry['original'],\n",
    "            'highest': highest,\n",
    "            'lowest': lowest\n",
    "        })\n",
    "\n",
    "        remaining = [samples[i] for i in range(len(samples)) if i not in (i_max, i_min) and scores[i] > 1]\n",
    "\n",
    "        if len(remaining):\n",
    "            new_entry = deepcopy(entry)\n",
    "            new_entry['samples'] = remaining\n",
    "            kept.append(new_entry)\n",
    "    else:\n",
    "        kept.append(deepcopy(entry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5509a9ec-0fde-443a-bdf1-2599fee59157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1770"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set_aside)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11eec170-8d85-4c28-8ac7-0ad8498b64a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4554"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "702aaf77-3ca3-45a5-b1ce-bebab8d4ebed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13772"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(x['samples']) for x in kept])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "960e3be8-5001-44bd-9775-c30f5d453750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39500d1f19714c9ebb8ee3425355afb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Qwen3ForCausalLM(\n",
       "  (model): Qwen3Model(\n",
       "    (embed_tokens): Embedding(151936, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-35): 36 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (down_proj): Linear(in_features=12288, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "    (rotary_emb): Qwen3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model.model import load_tokenizer, load_aligned_model, load_base_model\n",
    "\n",
    "tokenizer = load_tokenizer()\n",
    "model = load_aligned_model()\n",
    "ref_model = load_base_model()\n",
    "\n",
    "model.train()\n",
    "ref_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2c224a2-9b21-414a-ab6d-a68148173ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_end|>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fb67bb1-42ed-49a5-8876-431146f7d416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "peft.peft_model.PeftModelForCausalLM"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fb59997-26f7-4560-8067-a18c609e6b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eed7358c-9fce-40bb-8894-778b2447860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "EPOCHS = 3\n",
    "LR = 1e-4\n",
    "GRAD_ACCUM_STEPS = 1\n",
    "MAX_LENGTH = 512\n",
    "KL_LAMBDA = 0.1\n",
    "\n",
    "device = next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9a983d1-612a-49d9-82a6-bbab17b4fe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _join_trace(trace):\n",
    "    if isinstance(trace, (list, tuple)):\n",
    "        return \"\\n\".join(s.strip() for s in trace if s is not None)\n",
    "    return str(trace)\n",
    "\n",
    "examples = []\n",
    "raw_scores = [float(sc) for e in kept for _, sc in e.get(\"samples\", [])]\n",
    "if not raw_scores:\n",
    "    raise ValueError(\"kept contains no samples\")\n",
    "mn, mx = min(raw_scores), max(raw_scores)\n",
    "denom = max(1e-12, mx - mn)\n",
    "eos = tokenizer.eos_token or \"\"\n",
    "\n",
    "for e in kept:\n",
    "    prompt = e[\"prompt\"].strip()\n",
    "    for trace, score in e.get(\"samples\", []):\n",
    "        weight = (float(score) - mn) / denom\n",
    "        inp = prompt + eos\n",
    "        tgt = _join_trace(trace) + eos\n",
    "        inp_ids = tokenizer.encode(inp, add_special_tokens=False)\n",
    "        tgt_ids = tokenizer.encode(tgt, add_special_tokens=False)\n",
    "        if len(inp_ids) + len(tgt_ids) > MAX_LENGTH:\n",
    "            keep_tgt = MAX_LENGTH // 2\n",
    "            keep_inp = MAX_LENGTH - keep_tgt\n",
    "            inp_ids = inp_ids[-keep_inp:]\n",
    "            tgt_ids = tgt_ids[:keep_tgt]\n",
    "        input_ids = inp_ids + tgt_ids\n",
    "        labels = [-100] * len(inp_ids) + tgt_ids\n",
    "        examples.append({\"input_ids\": input_ids, \"labels\": labels, \"weight\": float(weight)})\n",
    "\n",
    "hf_ds = Dataset.from_list(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed607c29-37eb-486d-a035-f3bf3f970a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_collator(batch):\n",
    "    pad_id = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id\n",
    "    max_len = max(len(x[\"input_ids\"]) for x in batch)\n",
    "    input_ids = [x[\"input_ids\"] + [pad_id] * (max_len - len(x[\"input_ids\"])) for x in batch]\n",
    "    labels = [x[\"labels\"] + [-100] * (max_len - len(x[\"labels\"])) for x in batch]\n",
    "    attention_mask = [[1] * len(x[\"input_ids\"]) + [0] * (max_len - len(x[\"input_ids\"])) for x in batch]\n",
    "    weights = [x[\"weight\"] for x in batch]\n",
    "    return {\n",
    "        \"input_ids\": torch.tensor(input_ids, dtype=torch.long),\n",
    "        \"attention_mask\": torch.tensor(attention_mask, dtype=torch.long),\n",
    "        \"labels\": torch.tensor(labels, dtype=torch.long),\n",
    "        \"weights\": torch.tensor(weights, dtype=torch.float)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "342c9fa5-698e-4b7c-a19e-654329178bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "class WeightedSFTTrainer(Trainer):\n",
    "    def __init__(self, ref_model=None, kl_lambda=0.5, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.ref_model = ref_model\n",
    "        self.kl_lambda = kl_lambda\n",
    "        if self.ref_model is not None:\n",
    "            self.ref_model.to(self.model.device)\n",
    "            self.ref_model.eval()\n",
    "            for p in self.ref_model.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        weights = inputs.pop(\"weights\", None)\n",
    "        device = self.model.device\n",
    "        tensor_inputs = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in inputs.items()}\n",
    "    \n",
    "        if weights is None:\n",
    "            weights = torch.ones(tensor_inputs[\"labels\"].size(0), dtype=torch.float, device=device)\n",
    "        else:\n",
    "            weights = weights.to(device).float()\n",
    "    \n",
    "        labels = tensor_inputs[\"labels\"]\n",
    "        outputs = model(**tensor_inputs)\n",
    "        logits = outputs.logits  # (B, S, V)\n",
    "    \n",
    "        # --- SHIFT for causal LM: predict token t using logits at t-1 ---\n",
    "        shift_logits = logits[..., :-1, :].contiguous()          # (B, S-1, V)\n",
    "        shift_labels = labels[..., 1:].contiguous()             # (B, S-1)\n",
    "        mask = (shift_labels != -100).float()                   # (B, S-1)\n",
    "    \n",
    "        vocab = shift_logits.size(-1)\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(ignore_index=-100, reduction=\"none\")\n",
    "        flat_logits = shift_logits.view(-1, vocab)\n",
    "        flat_labels = shift_labels.view(-1)\n",
    "        token_losses = loss_fct(flat_logits, flat_labels).view(shift_labels.size(0), -1)\n",
    "    \n",
    "        token_loss_sum = (token_losses * mask).sum(dim=1)\n",
    "        denom = mask.sum(dim=1).clamp(min=1.0)\n",
    "        per_sample_ce = token_loss_sum / denom\n",
    "        weighted_ce = (per_sample_ce * weights).sum() / max(1e-12, weights.sum())\n",
    "        total_loss = weighted_ce\n",
    "    \n",
    "        # --- KL (compare next-token distributions) ---\n",
    "        if self.ref_model is not None and self.kl_lambda > 0:\n",
    "            with torch.no_grad():\n",
    "                ref_logits = self.ref_model(\n",
    "                    input_ids=tensor_inputs[\"input_ids\"],\n",
    "                    attention_mask=tensor_inputs.get(\"attention_mask\", None)\n",
    "                ).logits\n",
    "            ref_shift = ref_logits[..., :-1, :].contiguous()\n",
    "            ref_logp = F.log_softmax(ref_shift, dim=-1)\n",
    "            model_logp = F.log_softmax(shift_logits, dim=-1)\n",
    "            ref_p = torch.exp(ref_logp)\n",
    "            per_token_kl = (ref_p * (ref_logp - model_logp)).sum(dim=-1)    # (B, S-1)\n",
    "            per_sample_kl = (per_token_kl * mask).sum(dim=1) / denom\n",
    "            kl_weights = (1.0 - weights).clamp(min=0.0)\n",
    "            weighted_kl = (per_sample_kl * kl_weights).sum() / max(1e-12, kl_weights.sum())\n",
    "            total_loss = total_loss + self.kl_lambda * weighted_kl\n",
    "    \n",
    "        return (total_loss, outputs) if return_outputs else total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ca67e8c-c8c3-4468-acd8-6ff2be876c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4563/60206409.py:5: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedSFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10329' max='10329' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10329/10329 25:59, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.431200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.277800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.238000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.203600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.175100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.162400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.111900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.868700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.857100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.868100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.842600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.851700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.848000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.782800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.587100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.571200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.576800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.580600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.566900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.564000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10329, training_loss=0.887729242586861, metrics={'train_runtime': 1560.0149, 'train_samples_per_second': 26.484, 'train_steps_per_second': 6.621, 'total_flos': 3.068126449309532e+17, 'train_loss': 0.887729242586861, 'epoch': 3.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=OUT_DIR + \"/training-output\",\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    learning_rate=LR,\n",
    "    gradient_accumulation_steps=GRAD_ACCUM_STEPS,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=3,\n",
    "    remove_unused_columns=False,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = WeightedSFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=hf_ds,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    ref_model=ref_model if 'ref_model' in globals() else None,\n",
    "    kl_lambda=KL_LAMBDA\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1902862a-5abd-4177-adb3-0c7b7da2e738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from model.model import save_aligned_model\n",
    "# save_aligned_model(model)\n",
    "from model.model import load_aligned_model\n",
    "model = load_aligned_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0559fc68-5797-4188-b473-0250951ab855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((['Natalia sold 48 clips in April.',\n",
       "   'In May, she sold half as many clips as in April.',\n",
       "   'To find the number of clips sold in May, divide 48 by 2.',\n",
       "   'Add the number of clips sold in April and May to find the total.'],\n",
       "  '72'),\n",
       " (['Natalia sold 48 clips in April.',\n",
       "   'In May, she sold half as many, which is 48 รท 2 = 24.',\n",
       "   'Adding the number of clips sold in April and May gives the total.'],\n",
       "  '72'))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import augmentation\n",
    "\n",
    "p = \"Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\"\n",
    "\n",
    "t = 0.2\n",
    "ttr = augmentation.generate_cot_completion(p, [], model, tokenizer, temperature=t, debug=1)\n",
    "rtr = augmentation.generate_cot_completion(p, [], ref_model, tokenizer, temperature=t, debug=1)\n",
    "ttr, rtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c50192d3-47b9-4e31-ae7e-a24e9fc347b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['In May, she sold half as many, so 50 รท 2 = 25',\n",
       "  'Adding the number of clips sold in April and May gives the answer.'],\n",
       " '75')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmentation.generate_cot_completion(p, [\"Natalia sold 50 clips in April\"], model, tokenizer, temperature=t, debug=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6251b54b-b423-4a45-8800-4a9fa8caa960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([\"Wait, that doesn't make sense. Let me recheck.\",\n",
       "  'Natalia sold 48 clips in April.',\n",
       "  'In May, she sold half as many as in April, so 48 / 2 = 24 clips.',\n",
       "  'Adding the clips sold in April and May gives the total.'],\n",
       " '48 + 24 = 72 clips')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmentation.generate_cot_completion(p, [\"Natalia sold 48 / 6 = 8 clips in April\"], ref_model, tokenizer, temperature=t, debug=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "27952712-5ff8-42df-a779-be0312ad31fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "built DPO dataset: 1770 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prompt': 'Janet has nine oranges and Sharon has seven oranges. How many oranges do Janet and Sharon have together?',\n",
       " 'chosen': 'What is 77 divided by negative nine? It is negative eight point five five five five five six.\\nThe question was about the total number of oranges.<|im_end|>',\n",
       " 'rejected': 'Janet has 9 oranges.\\nSharon has 7 oranges.\\nAdding the Kijkwijzer rating of Tell Me a Riddle gives AL.<|im_end|>',\n",
       " 'chosen_score': 5.772365570068359,\n",
       " 'rejected_score': 0.042171478271484375}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 1: build preference dataset (prompt, chosen, rejected) from set_aside\n",
    "from datasets import Dataset\n",
    "eos = tokenizer.eos_token or \"\"\n",
    "rows = []\n",
    "\n",
    "def safe_join_trace(trace):\n",
    "    if isinstance(trace, (list, tuple)):\n",
    "        return \"\\n\".join(s.strip() for s in trace if s is not None).strip()\n",
    "    return str(trace).strip()\n",
    "\n",
    "for e in set_aside:\n",
    "    try:\n",
    "        prompt = e[\"prompt\"].strip()\n",
    "        chosen_trace, chosen_score = e[\"highest\"]\n",
    "        rejected_trace, rejected_score = e[\"lowest\"]\n",
    "    except Exception:\n",
    "        continue\n",
    "    chosen = safe_join_trace(chosen_trace)\n",
    "    rejected = safe_join_trace(rejected_trace)\n",
    "    if not prompt or not chosen or not rejected:\n",
    "        continue\n",
    "    rows.append({\n",
    "        \"prompt\": prompt,\n",
    "        \"chosen\": chosen + eos,\n",
    "        \"rejected\": rejected + eos,\n",
    "        \"chosen_score\": float(chosen_score),\n",
    "        \"rejected_score\": float(rejected_score),\n",
    "    })\n",
    "\n",
    "if not rows:\n",
    "    raise ValueError(\"No valid preference rows produced from set_aside\")\n",
    "\n",
    "dpo_ds = Dataset.from_list(rows)\n",
    "print(f\"built DPO dataset: {len(dpo_ds)} rows\")\n",
    "dpo_ds[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "957df6af-1939-4a95-8619-02536548613d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a425960540e64deaba3ca74d216c8da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting prompt in train dataset:   0%|          | 0/1770 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b675f104db3f4c79b3ee531facb1fef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/1770 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c9d713da7d1464db359b719d85f24eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/1770 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='443' max='443' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [443/443 01:42, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.129000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.047200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.190500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.071600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.881400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.853500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.078100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.062200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=443, training_loss=0.580721561849521, metrics={'train_runtime': 102.6298, 'train_samples_per_second': 17.246, 'train_steps_per_second': 4.316, 'total_flos': 0.0, 'train_loss': 0.580721561849521, 'epoch': 1.0})"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trl import DPOConfig, DPOTrainer\n",
    "\n",
    "dpo_cfg = DPOConfig(\n",
    "    output_dir=OUT_DIR + \"/dpo-output\",\n",
    "    per_device_train_batch_size=BATCH_SIZE if 'BATCH_SIZE' in globals() else 4,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=1e-6,\n",
    "    logging_steps=50,\n",
    "    report_to=[\"none\"]\n",
    ")\n",
    "\n",
    "trainer = DPOTrainer(\n",
    "    model=model,\n",
    "    args=dpo_cfg,\n",
    "    train_dataset=dpo_ds,\n",
    "    processing_class=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ec0da38f-89dc-4236-9ead-a400320517f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model (no hint): (['Natalia sold 48 clips in April.', 'In May, she sold half as many clips as in April.', 'To find the total, add the number of clips sold in April and May.'], '48 + (48 รท 2) = 48 + 24 = 72')\n",
      "ref   (no hint): (['Natalia sold 48 clips in April.', 'In May, she sold half as many as in April, which is 48 รท 2 = 24.', 'Adding the number of clips sold in April and May gives the total.'], '72')\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: save and rerun the same generation checks\n",
    "from model.model import save_aligned_model\n",
    "save_aligned_model(model)\n",
    "\n",
    "import augmentation\n",
    "p = \"Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\"\n",
    "t = 0.1\n",
    "\n",
    "print(\"model (no hint):\", augmentation.generate_cot_completion(p, [], model, tokenizer, temperature=t, debug=1))\n",
    "print(\"ref   (no hint):\", augmentation.generate_cot_completion(p, [], ref_model, tokenizer, temperature=t, debug=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "42f8441f-5580-4e29-a516-86587f8d9fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model (with hint): (['She sold half as many in May, so 4800 / 2 = 2400', 'Adding 800 and 2400 gives the answer.'], '3200')\n",
      "ref   (with hint): ([\"Wait, that doesn't make sense. Let me re-examine the problem.\", 'Natalia sold 48 clips in April.', 'She sold half as many in May, so 48 / 2 = 24 clips in May.', 'Adding the clips sold in April and May gives the total.'], '48 + 24 = 72 clips')\n"
     ]
    }
   ],
   "source": [
    "print(\"model (with hint):\", augmentation.generate_cot_completion(p, [\"Natalia sold 4800 / 6 = 800 clips in April\"], model, tokenizer, temperature=t, debug=0.1))\n",
    "print(\"ref   (with hint):\", augmentation.generate_cot_completion(p, [\"Natalia sold 48 / 6 = 8 clips in April\"], ref_model, tokenizer, temperature=t, debug=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3701ca-4506-4d2b-a2c0-1b9d08549850",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
