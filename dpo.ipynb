{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08d46086-7679-4ad2-84ef-ad9ffb27c10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ecbd01c-817b-4b0f-90bd-cc056d1a65e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2026-01-02 04:22:00.438567: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-02 04:22:00.494318: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:06<00:00,  2.23s/it]\n"
     ]
    }
   ],
   "source": [
    "from model.model import reset_aligned_model\n",
    "reset_aligned_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf027105-2d52-4052-8781-3e75bfed0ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "from config import out_subdir\n",
    "PICKLE_PATH = os.path.join(out_subdir, \"datagen.pkl\")\n",
    "PICKLE_QA_PATH = os.path.join(out_subdir, \"datagen-qa.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa6a64fa-a273-49cc-9484-3110bf7273e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PICKLE_PATH, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "with open(PICKLE_QA_PATH, \"rb\") as f:\n",
    "    qa_data = pickle.load(f)\n",
    "    data.extend(qa_data[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6804ad47-8408-4793-8742-b1154b1f898d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [({**y, 'samples': [(z, w, i) for i, (z, w) in enumerate(y['samples']) if len(z) != i + 1]}) for y in data if len(y['samples'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "946984a8-d50a-455a-92e8-a47f7c76f424",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "from newdatagen import dataset_sources, format_entry, format_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c46b0622-345e-46d1-b285-09e9da2b8d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmap = dict()\n",
    "dsmap = dict()\n",
    "\n",
    "for k, v in dataset_sources.items():\n",
    "    # if \"qa\" in k: continue\n",
    "    for vv in v:\n",
    "        dsmap[format_entry(vv, k)] = k\n",
    "        # high faithfulness, low accuracy\n",
    "        # pmap[format_entry(vv, k)] = (format_answer(vv, k), (0.8 if \"gsm\" in k else 0.4 if \"qa\" in k else 0.8), (1.2 if \"qa\" in k else 0.75))\n",
    "        # medium faithfulness, high accuracy\n",
    "        # pmap[format_entry(vv, k)] = (format_answer(vv, k), (1.5 if \"gsm\" in k else 0.4 if \"qa\" in k else 0.8), (1.2 if \"qa\" in k else 0.75))\n",
    "        # bestest2\n",
    "        # pmap[format_entry(vv, k)] = (format_answer(vv, k), (1.5 if \"gsm\" in k else 0.4 if \"qa\" in k else 0.8), (1.0 if \"qa\" in k else 1.0))\n",
    "        # bestest3\n",
    "        # pmap[format_entry(vv, k)] = (format_answer(vv, k), (1.0 if \"gsm\" in k else 0.4 if \"qa\" in k else 0.8), (1.0 if \"qa\" in k else 1.0))\n",
    "        # bestest4\n",
    "        # pmap[format_entry(vv, k)] = (format_answer(vv, k), (1.0 if \"gsm\" in k else 0.4 if \"qa\" in k else 0.8), (1.0 if \"qa\" in k else 1.0))\n",
    "        pmap[format_entry(vv, k)] = (format_answer(vv, k), (1.8 if \"gsm\" in k else 0.4 if \"qa\" in k else 0.8), (1.0 if \"qa\" in k else 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84e9e067-462b-4a4e-b438-387be3ec9d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'commonsenseqa': 341, 'gsm8k': 212, 'asdiv': 44, 'svamp': 22, 'strategyqa': 8, 'scibench': 20})\n"
     ]
    }
   ],
   "source": [
    "kept = []\n",
    "set_aside = []\n",
    "l, h = 0.5, 12\n",
    "\n",
    "from collections import defaultdict\n",
    "sources = defaultdict(int)\n",
    "for entry in data:\n",
    "    sources[dsmap[entry['prompt']]] += 1\n",
    "    samples = entry.get('samples', [])\n",
    "\n",
    "    outside = [s for s in samples if s[1] < l or s[1] > h]\n",
    "\n",
    "    if outside:\n",
    "        set_aside.append({\n",
    "            'prompt': entry['prompt'],\n",
    "            'original': entry['original'],\n",
    "            'samples': outside\n",
    "        })\n",
    "\n",
    "    inside = [s for s in samples if s[1] >= l and s[1] <= h]\n",
    "\n",
    "    if inside:\n",
    "        new_entry = deepcopy(entry)\n",
    "        new_entry['samples'] = inside\n",
    "        new_entry['answer'] = pmap[entry['prompt']][0] if entry['prompt'] in pmap else None\n",
    "        new_entry['answer_weight'] = pmap[entry['prompt']][1] if entry['prompt'] in pmap else 0\n",
    "        new_entry['mult'] = pmap[entry['prompt']][2] if entry['prompt'] in pmap else 1.0\n",
    "        kept.append(new_entry)\n",
    "\n",
    "print(sources)\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(kept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5509a9ec-0fde-443a-bdf1-2599fee59157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "391"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set_aside)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a312a85d-3aad-4dcd-a841-e75e65bb7cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kept = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11eec170-8d85-4c28-8ac7-0ad8498b64a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "534"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "702aaf77-3ca3-45a5-b1ce-bebab8d4ebed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1698"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(x['samples']) for x in kept])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc50ee74-539e-4bac-b458-7bfece89bce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "647"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "960e3be8-5001-44bd-9775-c30f5d453750",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:06<00:00,  2.21s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32768, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): MistralRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32768, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model.model import load_tokenizer, load_aligned_model, load_base_model\n",
    "\n",
    "tokenizer = load_tokenizer()\n",
    "model = load_aligned_model()\n",
    "ref_model = load_base_model()\n",
    "\n",
    "model.train()\n",
    "ref_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fb59997-26f7-4560-8067-a18c609e6b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eed7358c-9fce-40bb-8894-778b2447860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import BATCH_SIZE, EPOCHS, LR, GRAD_ACCUM_STEPS, MAX_LENGTH, KL_LAMBDA\n",
    "# bestest1\n",
    "# EPOCHS = 1\n",
    "# LR = 5e-5\n",
    "# bestest2\n",
    "# EPOCHS = 1\n",
    "# LR = 7e-5\n",
    "EPOCHS = 1\n",
    "LR = 7e-5\n",
    "# high faithfulness, low accuracy\n",
    "# KL_LAMBDA = 0.2\n",
    "# bestest1\n",
    "# KL_LAMBDA = 0.5\n",
    "# bestest2\n",
    "# KL_LAMBDA = 2.5\n",
    "# bestest3\n",
    "# KL_LAMBDA = 2.0\n",
    "# bestest4\n",
    "# KL_LAMBDA = 1.6\n",
    "# bestest5\n",
    "# KL_LAMBDA = 1.2\n",
    "KL_LAMBDA = 0.8\n",
    "device = next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "066e3505-fac7-41c1-95f0-b241661820aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'At the bake sale, Tamara makes $32 from the brownies. She made 2 pans of brownies which were all sold.  The brownies were cut into 8 big square pieces.  How much did each brownie cost?',\n",
       " 'original': (['The question provides that the brownies were cut into 8 big square pieces.',\n",
       "   'The total earnings from the brownies are $32.',\n",
       "   'The number of pieces is 8.',\n",
       "   'Dividing $32 by 8 gives the cost of each brownie.'],\n",
       "  '4'),\n",
       " 'samples': [(['The year provides that it is the 428th year in the Julian calendar.',\n",
       "    'The Julian leap year interval is approximately 365.25 days per year.',\n",
       "    'However, this is more of a trivia fact about the calendar and not required to answer this question.',\n",
       "    'To answer the question:',\n",
       "    '2 pans were made, each consisting of 8x8 square pieces.',\n",
       "    'The price of baking is asked over the whole batch.',\n",
       "    'To find the average cost per square from the sale we have;',\n",
       "    '32(in thousands so it is the total number of dollars made multiplied by 100 to represent the dollars as an integer)= 3200',\n",
       "    '2(for to pans made) * 8 * 8 (number of pieces) = 256 pieces and to find the cost per one piece divide whole cost to it;',\n",
       "    '6.25 $ since each batch of brownies provides for (5/9) pieces more when cut using this method.'],\n",
       "   1.5411376953125,\n",
       "   0),\n",
       "  (['The question provides that the brownies were cut into 8 big square pieces.',\n",
       "    '322 is a natural number.',\n",
       "    'We cannot divide 32 by any positive proper divisor including 2, 8, and 16.',\n",
       "    'The only way 32 can be found is to multiply two lesser numbers and divide the result by 1.',\n",
       "    'Hence, the possible options are 1 × 32, 2 × 16, or a factorization that sum up lesser numbers than 6.',\n",
       "    'Out of these factors, (16 - the largest factorization below 6), multiples only up to factor less than 6 will give exactly two whole numbers when adding. These remainders are found to be (3), (5), & (7).',\n",
       "    'The possible factors can thus be expressed as {8k-1 & 8k+1} or just (3 × 4^i k = 3-2i, i ε Integer), as { (3 -5 + (7 - 13 + ... ) } does not contribute as both odd, are only one time value due to factorial pattern, are non - multiples of 32 except for k=1.',\n",
       "    'Testing only the lowest factors which are (0,1):',\n",
       "    'k = 0 does not divide exactly 25 (number of pieces) but by multiplying k=1 & 4 we get total = 32.',\n",
       "    'k=0: 8 \\\\* 1 \\\\* 1 * 4 =32'],\n",
       "   0.7794189453125,\n",
       "   1),\n",
       "  (['The question provides that the brownies were cut into 8 big square pieces.',\n",
       "    'The total earnings from the brownies are $32.',\n",
       "    'The 1590s include the year 1598.',\n",
       "    'False, because our current age was greater than or equal to 1 in  years after 1569, while our current age was less than the year  1783. False is only true if, and only if, at least one element contradicts all of the other elements of the list, as per the conditions given in the question. (Since both conditions for 1598 and 1st century are already ruled out due to the ages greater than years after 1569 and less than the  year 1682, \"false\" is definitely the appropriate answer.)',\n",
       "    'Answer:False'],\n",
       "   0.9844970703125,\n",
       "   2),\n",
       "  (['The question provides that the brownies were cut into 8 big square pieces.',\n",
       "    'The total earnings from the brownies are $32.',\n",
       "    'The number of pieces is 8.',\n",
       "    'Dividing 322 by 1 gives the number of brownies.',\n",
       "    'The number of brownies was previously noted as 2 (from2 pans).',\n",
       "    'The product 2 × 8 gives the number of individual pieces (16) divided by what 32∣832.',\n",
       "    'The answer is the quotient 16÷32.',\n",
       "    'However, the answer should be the price of one large brownie, so multiplying the result by10∣8 gets the total price anddividing that number by 8 gets the average unit price. Result: $2'],\n",
       "   0.6343994140625,\n",
       "   3)],\n",
       " 'answer': '2',\n",
       " 'answer_weight': 1.8,\n",
       " 'mult': 1.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kept[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9a983d1-612a-49d9-82a6-bbab17b4fe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _join_trace(trace):\n",
    "    if isinstance(trace, (list, tuple)):\n",
    "        return \"\\n\".join(s.strip() for s in trace if s is not None)\n",
    "    return str(trace)\n",
    "\n",
    "examples = []\n",
    "raw_scores = [float(sc) for e in kept for _, sc, _ in e.get(\"samples\", [])]\n",
    "if not raw_scores:\n",
    "    raise ValueError(\"kept contains no samples\")\n",
    "mn, mx = min(raw_scores), max(raw_scores)\n",
    "denom = max(1e-12, mx - mn)\n",
    "eos = tokenizer.eos_token or \"\"\n",
    "\n",
    "for e in kept:\n",
    "    prompt = e[\"prompt\"].strip()\n",
    "    avg = 0\n",
    "    for trace, score, step in e.get(\"samples\", []):\n",
    "        weight = (float(score) - mn) / denom\n",
    "        weight = (0.05 + 0.95 * weight) ** (1/2)\n",
    "        # add_ans = weight >= 0.7\n",
    "        add_ans = weight >= 0.4\n",
    "        weight *= e['mult']\n",
    "        avg += weight\n",
    "        inp = f\"Q: {prompt}\\nReasoning:\\n{_join_trace(trace[:step+1])}\\n\"\n",
    "        tgt = f\"{_join_trace(trace[step+1:])}\"\n",
    "        ans = None\n",
    "        if add_ans and e['answer'] is not None:\n",
    "            tgt += \"\\n\"\n",
    "            ans = f\"Answer: {e['answer']}\\n\\n\"\n",
    "        inp_ids = tokenizer.encode(inp, add_special_tokens=False)\n",
    "        tgt_ids = tokenizer.encode(tgt, add_special_tokens=False)\n",
    "        token_weights = [0] * len(inp_ids) + [weight] * len(tgt_ids)\n",
    "        if ans is not None:\n",
    "            ans_ids = tokenizer.encode(ans, add_special_tokens=False)\n",
    "            tgt_ids += ans_ids\n",
    "            token_weights += [e['answer_weight'] * weight] * len(ans_ids)\n",
    "        if len(inp_ids) + len(tgt_ids) > MAX_LENGTH:\n",
    "            continue\n",
    "            # keep_tgt = MAX_LENGTH // 2\n",
    "            # keep_inp = MAX_LENGTH - keep_tgt\n",
    "            # inp_ids = inp_ids[-keep_inp:]\n",
    "            # tgt_ids = tgt_ids[:keep_tgt]\n",
    "        input_ids = inp_ids + tgt_ids\n",
    "        labels = [-100] * len(inp_ids) + tgt_ids\n",
    "        # examples.append({\"input_ids\": input_ids, \"labels\": labels, \"weight\": float(weight)})\n",
    "        examples.append({\"input_ids\": input_ids, \"labels\": labels, \"token_weights\": token_weights})\n",
    "    # if e['answer'] is None:\n",
    "    #     continue\n",
    "    # avg /= len(e[\"samples\"])\n",
    "    # inp = f\"Q: {prompt}\\nReasoning:\\n{_join_trace(e['original'][0])}\\n\"\n",
    "    # tgt = f\"Answer: {e['answer']}{eos}\"\n",
    "    # inp_ids = tokenizer.encode(inp, add_special_tokens=False)\n",
    "    # tgt_ids = tokenizer.encode(tgt, add_special_tokens=False)\n",
    "    # if len(inp_ids) + len(tgt_ids) > MAX_LENGTH:\n",
    "    #     keep_tgt = MAX_LENGTH // 2\n",
    "    #     keep_inp = MAX_LENGTH - keep_tgt\n",
    "    #     inp_ids = inp_ids[-keep_inp:]\n",
    "    #     tgt_ids = tgt_ids[:keep_tgt]\n",
    "    # input_ids = inp_ids + tgt_ids\n",
    "    # labels = [-100] * len(inp_ids) + tgt_ids\n",
    "    # examples.append({\"input_ids\": input_ids, \"labels\": labels, \"weight\": e[\"answer_weight\"]})\n",
    "hf_ds = Dataset.from_list(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed607c29-37eb-486d-a035-f3bf3f970a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_collator(batch):\n",
    "    pad_id = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id\n",
    "    max_len = max(len(x[\"input_ids\"]) for x in batch)\n",
    "    input_ids = [x[\"input_ids\"] + [pad_id] * (max_len - len(x[\"input_ids\"])) for x in batch]\n",
    "    labels = [x[\"labels\"] + [-100] * (max_len - len(x[\"labels\"])) for x in batch]\n",
    "    attention_mask = [[1] * len(x[\"input_ids\"]) + [0] * (max_len - len(x[\"input_ids\"])) for x in batch]\n",
    "    # weights = [x[\"weight\"] for x in batch]\n",
    "    token_weights = [x[\"token_weights\"] + [0] * (max_len - len(x[\"token_weights\"])) for x in batch]\n",
    "    return {\n",
    "        \"input_ids\": torch.tensor(input_ids, dtype=torch.long),\n",
    "        \"attention_mask\": torch.tensor(attention_mask, dtype=torch.long),\n",
    "        \"labels\": torch.tensor(labels, dtype=torch.long),\n",
    "        # \"weights\": torch.tensor(weights, dtype=torch.float)\n",
    "        \"token_weights\": torch.tensor(token_weights, dtype=torch.float)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "342c9fa5-698e-4b7c-a19e-654329178bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "class WeightedSFTTrainer(Trainer):\n",
    "    def __init__(self, ref_model=None, kl_lambda=0.5, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.ref_model = ref_model\n",
    "        self.kl_lambda = kl_lambda\n",
    "        if self.ref_model is not None:\n",
    "            self.ref_model.to(self.model.device)\n",
    "            self.ref_model.eval()\n",
    "            for p in self.ref_model.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        # weights = inputs.pop(\"weights\", None)\n",
    "        token_weights = inputs.pop(\"token_weights\", None)\n",
    "        device = self.model.device\n",
    "        tensor_inputs = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in inputs.items()}\n",
    "    \n",
    "        # if weights is None:\n",
    "        #     weights = torch.ones(tensor_inputs[\"labels\"].size(0), dtype=torch.float, device=device)\n",
    "        # else:\n",
    "        #     weights = weights.to(device).float()\n",
    "        token_weights = token_weights.to(device).float()[..., 1:].contiguous()\n",
    "    \n",
    "        labels = tensor_inputs[\"labels\"]\n",
    "        outputs = model(**tensor_inputs)\n",
    "        logits = outputs.logits  # (B, S, V)\n",
    "    \n",
    "        # --- SHIFT for causal LM: predict token t using logits at t-1 ---\n",
    "        shift_logits = logits[..., :-1, :].contiguous()          # (B, S-1, V)\n",
    "        shift_labels = labels[..., 1:].contiguous()             # (B, S-1)\n",
    "        mask = (shift_labels != -100).float()                   # (B, S-1)\n",
    "    \n",
    "        vocab = shift_logits.size(-1)\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(ignore_index=-100, reduction=\"none\")\n",
    "        flat_logits = shift_logits.view(-1, vocab)\n",
    "        flat_labels = shift_labels.view(-1)\n",
    "        token_losses = loss_fct(flat_logits, flat_labels).view(shift_labels.size(0), -1) * mask\n",
    "    \n",
    "        # token_loss_sum = (token_losses * mask).sum(dim=1)\n",
    "        token_loss_sum = (token_losses * token_weights).sum(dim=1)\n",
    "        denom = token_weights.sum(dim=1).clamp(min=1.0)\n",
    "        per_sample_ce = (token_losses * token_weights).sum(dim=1) / denom\n",
    "        # weighted_ce = (per_sample_ce * weights).sum() / max(1e-12, weights.sum())\n",
    "        weighted_ce = per_sample_ce.mean()\n",
    "        total_loss = weighted_ce\n",
    "    \n",
    "        # --- KL (compare next-token distributions) ---\n",
    "        if self.ref_model is not None and self.kl_lambda > 0:\n",
    "            with torch.no_grad():\n",
    "                ref_logits = self.ref_model(\n",
    "                    input_ids=tensor_inputs[\"input_ids\"],\n",
    "                    attention_mask=tensor_inputs.get(\"attention_mask\", None)\n",
    "                ).logits\n",
    "            ref_shift = ref_logits[..., :-1, :].contiguous()\n",
    "            ref_logp = F.log_softmax(ref_shift, dim=-1)\n",
    "            model_logp = F.log_softmax(shift_logits, dim=-1)\n",
    "            ref_p = torch.exp(ref_logp)\n",
    "            per_token_kl = (ref_p * (ref_logp - model_logp)).sum(dim=-1)    # (B, S-1)\n",
    "            # per_sample_kl = (per_token_kl * mask).sum(dim=1) / denom\n",
    "            per_sample_kl = (per_token_kl * token_weights).sum(dim=1) / denom\n",
    "            # kl_weights = (1.0 - weights).clamp(min=0.0)\n",
    "            weighted_kl = per_sample_kl.mean()\n",
    "            total_loss = total_loss + self.kl_lambda * weighted_kl\n",
    "    \n",
    "        return (total_loss, outputs) if return_outputs else total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ca67e8c-c8c3-4468-acd8-6ff2be876c88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31119/1984371358.py:5: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedSFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n",
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 2}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='425' max='425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [425/425 02:18, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.437600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.404700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.348500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.380600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.379400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.374300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.330700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=425, training_loss=2.3622918342141546, metrics={'train_runtime': 139.5091, 'train_samples_per_second': 12.171, 'train_steps_per_second': 3.046, 'total_flos': 3.260405183378227e+16, 'train_loss': 2.3622918342141546, 'epoch': 1.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=out_subdir + \"/training-output\",\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    learning_rate=LR,\n",
    "    gradient_accumulation_steps=GRAD_ACCUM_STEPS,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=3,\n",
    "    remove_unused_columns=False,\n",
    "    report_to=\"none\",\n",
    "    logging_steps=50,\n",
    ")\n",
    "\n",
    "trainer = WeightedSFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=hf_ds,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    ref_model=ref_model if 'ref_model' in globals() else None,\n",
    "    # ref_model=None,\n",
    "    kl_lambda=KL_LAMBDA\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1902862a-5abd-4177-adb3-0c7b7da2e738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.model import save_aligned_model\n",
    "save_aligned_model(model)\n",
    "# from model.model import load_aligned_model\n",
    "# model = load_aligned_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0559fc68-5797-4188-b473-0250951ab855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((['Alice starts with 7 sflkjs.',\n",
       "   'She breaks 3 sflkjs, which now belong to her.',\n",
       "   'The original 3 sflkjs are lost.',\n",
       "   'Adding the 3 new sflkjs to the remaining 4 gives the answer, 7.'],\n",
       "  '7'),\n",
       " (['Alice starts with 7 sflkjs.',\n",
       "   'She breaks 3 sflkjs, which now become 6 new sflkjs.',\n",
       "   'Adding the original 7 sflkjs and the new 6 sflkjs gives the answer, 13.'],\n",
       "  '13'))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import augmentation\n",
    "\n",
    "# p = \"Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\"\n",
    "p = \"Alice has 7 sflkjs. When a sflkj is broken, it divides into two new sflkjs which now belong to Alice, and the original sflkj is lost. If Alice breaks 3 sflkjs, how many sflkjs does she have now?\"\n",
    "\n",
    "t = 0.01\n",
    "ttr = augmentation.generate_cot_completion(p, [], model, tokenizer, temperature=t, debug=1)\n",
    "rtr = augmentation.generate_cot_completion(p, [], ref_model, tokenizer, temperature=t, debug=1)\n",
    "ttr, rtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c50192d3-47b9-4e31-ae7e-a24e9fc347b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], '16')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmentation.generate_cot_completion(p, [\"Natalia sold 48 / 3 = 16 clips in April and half as many in May\"], model, tokenizer, temperature=t, debug=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6251b54b-b423-4a45-8800-4a9fa8caa960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['So, she sold 16 + 16 / 2 = 24 + 8 = 32 clips altogether.'], '32')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmentation.generate_cot_completion(p, [\"Natalia sold 48 / 3 = 16 clips in April and half as many in May\"], ref_model, tokenizer, temperature=t, debug=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972bf9aa-751f-4ff8-9365-bad4607ef298",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
